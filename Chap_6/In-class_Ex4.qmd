---
title: "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method"
editor: visual
---

## Overview

In this hands-on exercise, I learned how to build [hedonic pricing](https://www.investopedia.com/terms/h/hedonicpricing.asp) models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational.

## Getting Started

Firstly, we need to install the required R packages.

-   **olsrr:** building ordinary least squares regression models

-   **GWmodel:** building geographically weighted regression models

-   **corrplot:** plotting the graph of the correlation matrix

-   **sf**: importing, managing and processing geospatial data.

-   **tmap**: plotting Thematic Maps.

-   **tidyverse**: importing, wrangling and visualizing data. It consists of a family of R packages, including **readr**, **readxl**, **tidyr**, **dplyr** and **ggplot2**.

```{r}
pacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)

```

## Importing Required Data

### Importing geospatial data

The following codes import URA Master Plan 2014's planning subzone boundaries shapefile into R as a polygon feature data frame.

```{r}
mpsz <- st_read(dsn = "data/geospatial",
                 layer = "MP14_SUBZONE_WEB_PL")

```

The imported simple feature data frame is a multipolygon object. It contains 323 features and 15 fields. In addition, it's in SVY21 Coordinate System. However, it doesn't have EPSG information.

### Updating CRS information

```{r}
mpsz_svy21 <- st_transform(mpsz, 3414)
st_crs(mpsz_svy21)

```

Now the EPSG is indicated as 3414.

We could view the extent of the coordinates.

```{r}
st_bbox(mpsz_svy21)

```

### Importing the aspatial data

The following code chunk imports *Condo_resale_2015* data set into R as a tibble data frame. The data is extracted from The 2014 Myanmar Population and Housing Census Myanmar.

```{r}
condo_resale <- read_csv("data/aspatial/Condo_resale_2015.csv")

```

The ict tibble data frame has 1436 rows and 23 columns.

```{r}
glimpse(condo_resale)

```

The data looks good by verifying the first few rows.

```{r}
summary(condo_resale)

```

The summary report shows that there isn't any missing data in the data, and the values are in the reasonable ranges.

### Converting aspatial data frame into a sf object

```{r}
condo_resale.sf <- st_as_sf(condo_resale,
                            coords = c("LONGITUDE", "LATITUDE"),
                            crs=4326) %>%
  st_transform(crs=3414)

```

As the longitude and latitude variables are in decimal format, we could assume that the data is in WGS84 coordinate system. We converted it to SVY21 coordinate system so we could join it with the geospatial data.

```{r}
head(condo_resale.sf)

```

The original longitude and latitude columns are now replaced by a geometry column.

## Exploratory Data Analysis (EDA)

Let's do some exploration to have a better understanding on the data.

### EDA using statistical graphics

First of all, let check the distribution of the response variable, *SELLING_PRICE.*

```{r}
ggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

```

The plot shows that the selling price of codo in 2015 follows a right skewed distribution, which means there are more units with a relatively lower selling price.

We could do a log transformation to normalize the selling price distribution if necessary.

```{r}
condo_resale.sf <- condo_resale.sf %>%
  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))

ggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

```

The data in the plot above looks more like to a normal distribution now, but it's still slightly skewed to the right.

### Multiple histogram plots distribution of variables

Next, let's look at the distribution of the other numerical variables.

```{r fig.width = 10, fig.height = 10}
AREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + 
  geom_histogram(bins=20, color="black", fill="light blue")

AGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + 
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, 
                               aes(x= `PROX_URA_GROWTH_AREA`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, 
                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

ggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, 
          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,
          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  
          ncol = 3, nrow = 4)

```

The plots above shows that some variables are following a normal distribution, for example, PROX_CBD. On the other hands, most of the variables are right skewed. For example, AGE and PROX_CHILDCARE.

### Drawing statistical point map

Next, let's check the geospatial distribution of the selling price.

```{r}
tmap_mode("view")

tm_shape(mpsz_svy21)+
  tmap_options(check.and.fix = TRUE) +
  tm_polygons() +
tm_shape(condo_resale.sf) +  
  tm_dots(col = "SELLING_PRICE",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))

tmap_mode("plot")

```

The plot above shows that the high selling points are most in the central area. The units in east and west are in the middle, and the selling price in the north is the lowest in Singapore.

## Hedonic Pricing Modelling in R

Now, we'll build hedonic pricing models for condo resale units.

### Simple Linear Regression Method

Let's first build a simple linear regression model using one independent variable, *AREA_SQM.*

```{r}
condo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)

summary(condo.slr)

```

The summary tells us:

-   F-statistic: the p-value is less than 0.05, which indicates that the model is a good fit of the selling price at 5% significance level

-   Adjusted R-squared: in indicates that the model is able to explain 45.15% of the variation in condo selling price

-   Coefficients: the small (i.e., \< 0.05) p-value indicates that AREA_SQM is a significant factor in explaining the selling price. The positive coefficient tells that it has a positive relationship with the selling price. in other words, the selling price would increase by 14,719 for every 1 square meter increase in the unit area.

Now, let's plot the best fit line on the scatterplot.

```{r}
ggplot(data=condo_resale.sf,  
       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +
  geom_point() +
  geom_smooth(method = lm)

```

The plot above shows that the model couldn't do well for the larger units with higher resale prices.

The low adjusted R-square tells us that more independent variables are required to explain the selling price.

### Multiple linear regression method

One of the assumptions of multi-linear regression model is that all the independent variables are independent to each other. Therefore, let's check the correlation among the independent variables to avoid multicollinearity.

```{r fig.width=10, fig.height=10}
corrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = "AOE",
         tl.pos = "td", tl.cex = 0.5, method = "number", type = "upper")

```

The correlation matrix tells that there are indeed two variables, Freehold and LEASE_99YEAR, are strongly negatively correlated with correlation coefficient being -0.84. Hence, we need to exclude one of them while building the model. In this exercise, we will exclude LEASE_99YEAR is excluded from the model.

### Building a hedonic pricing model using multiple linear regression method

We'll use all the other variables in the data frame as the independent variables in the model, except LEASE_99YEAR.

```{r}
condo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + 
                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + 
                  PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + 
                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + 
                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                data=condo_resale.sf)

summary(condo.mlr)

```

The summary report tells us:

-   F-statistic: the p-value is less than 0.05, which indicates that the model is a good fit of the selling price at 5% significance level

-   Adjusted R-squared: in indicates that the model is able to explain 64.74% of the variation in condo selling price. There is an improvement of about 20% in the explained variation comparing to the simple linear regression model using only AREA_SQM as the independent variable.

-   Coefficients: the p-values reveals that some independent variables are significant (e.g., AREA_SQM, AGE), and some are not (e.g., PROX_HAWKER_MARKET, PROX_KINDERGARTEN).

### Preparing publication quality table: olsrr method

Next, we'll remove the insignificant variables and build the model again.

```{r}
condo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                   PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + 
                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + 
                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,
                 data=condo_resale.sf)

ols_regress(condo.mlr1)

```

The summary tells us:

-   F-statistic: the p-value is less than 0.05, which indicates that the model is a good fit of the selling price at 5% significance level

-   Adjusted R-squared: in indicates that the model is able to explain 64.7% of the variation in condo selling price. This is the same as the full model although less independent variables are used. Therefore, this model is better than the full model.

-   Coefficients: the p-values reveals that all the independent variables in this model are significant.

    -   Variables having positive impact on the selling price:

        -   AREA_SQM, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_PARK, PROX_PRIMARY_SCH, PROX_BUS_STOP, FAMILY_FRIENDLY, FREEHOLD

    -   variables having negative impact on the selling price:

        -   AGE, PROX_CBD, PROX_CHILDCARE, PROX_MRT, PROX_SHOPPING_MALL, NO_Of_UNITS

### Preparing publication quality table: gtsummary method

We could make the model summary look better by using gtsummary.

```{r}
tbl_regression(condo.mlr1, intercept = TRUE)

```

In addition to the default information about the independent variables, we could also append the model statistics in the table.

```{r}
tbl_regression(condo.mlr1, 
               intercept = TRUE) %>% 
  add_glance_source_note(
    label = list(sigma ~ "\U03C3"),
    include = c(r.squared, adj.r.squared, 
                AIC, statistic,
                p.value, sigma))

```

R-squared, adjusted R-squared, AIC, F statistic, p-value of the F test, as well as the sigma are added at the bottom of the table now.

### Checking for multicollinearity

Besides correlation matrix, VIF is another method to check if any independent variables are strongly correlated. Let's check VIF for the significant variables.

```{r}
ols_vif_tol(condo.mlr1)

```

The lower the VIF score, the more independent the variables are. 10 is a common cutoff point used to determine if multicollinearity exists. Since all the VIFs are less than 10 in the report above, we could conclude that the independent variables are independent.

### Test for non-linearity

Another assumption to check for multi linear regression model is the linearity and additivity of the relationship between dependent and independent variables.

```{r}
ols_plot_resid_fit(condo.mlr1)

```

As the residuals are mostly scattered around 0, we could conclude that the independent variables and the dependent variable are linearly related. Nevertheless, we do observe a larger deviation at the region with high fitted values. This could indicate that the model performs worse in that region, and we might need to construct separate models for low price units and high price units.

### Test for normality assumption

We also need to check if the residuals are normally distributed.

```{r}
ols_plot_resid_hist(condo.mlr1)

```

The histogram and the density curve show that the residuals generally follows a normal distribution.

```{r}
ols_test_normality(condo.mlr1)

```

The small p-values, \< 0.05, in the report above confirm that the residuals are normally distributed.

### Testing for spatial autocorrelation

The hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visualize the residual of the hedonic pricing model.

In order to perform spatial autocorrelation test, we need to convert *condo_resale.sf* from sf data frame into a SpatialPointsDataFrame.

We first export the residuals of the hedonic model to a data frame.

```{r}
mlr.output <- as.data.frame(condo.mlr1$residuals)

```

We then join the residual data frame with the *condo_resale.sf* object.

```{r}
condo_resale.res.sf <- cbind(condo_resale.sf, 
                        condo.mlr1$residuals) %>%
rename(`MLR_RES` = `condo.mlr1.residuals`)

```

Next, we convert the *condo_resale.res.sf* from simple feature object into a SpatialPointsDataFrame object.

```{r}
condo_resale.sp <- as_Spatial(condo_resale.res.sf)
condo_resale.sp

```

Now, we could display the distribution of the residuals on an interactive map.

```{r}
tmap_mode("view")

tm_shape(mpsz_svy21)+
  tmap_options(check.and.fix = TRUE) +
  tm_polygons(alpha = 0.4) +
tm_shape(condo_resale.res.sf) +  
  tm_dots(col = "MLR_RES",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))

tmap_mode("plot")

```

The plot above shows signs of spatial autocorrelation. Let's use Moran's I test to verify the result.

We first compute the distance-based weight matrix.

```{r}
nb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)
summary(nb)

```

Next, we convert the neighbours list into a spatial weights with equal weights applied to each neighbour.

```{r}
nb_lw <- nb2listw(nb, style = 'W')
summary(nb_lw)

```

Now we could carry out the Moran's I test for residual spatial autocorrelation.

```{r}
lm.morantest(condo.mlr1, nb_lw)

```

The summary report above shows that the p-value is less than 0.05. Hence, there is enough evidence for us to conclude that the model residuals are spatially autocorrelated. The positive Moran's I statistic of 0.144 confirms that the model residuals are spatially clustered.

## Building Hedonic Pricing Model using GWmodel

Next, we build hedonic pricing model using both the fixed and adaptive bandwidth schemes.

### Building fixed bandwidth GWR model

**Computing fixed bandwidth**

There are two ways to determine the optimal bandwidth:

-   CV cross-validation approach

-   AIC corrected (AICc) approach

We use CV approach in this exercise.

```{r}
bw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + 
                     PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + 
                     PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + 
                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + 
                     FAMILY_FRIENDLY + FREEHOLD, 
                   data=condo_resale.sp, 
                   approach="CV", 
                   kernel="gaussian", 
                   adaptive=FALSE, 
                   longlat=FALSE)

```

The result above shows that the optimal bandwidth is 971.3405 meters. The bandwidth is in meters because the projection system we are using, SVY21, is in meters.

**GWModel method - fixed bandwidth**

Now, we'll calibrate the gwr model using fixed bandwidth and gaussian kernel.

```{r}
gwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + 
                         PROX_CHILDCARE + PROX_ELDERLYCARE  + 
                         PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +
                         PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + 
                         PROX_BUS_STOP + NO_Of_UNITS + 
                         FAMILY_FRIENDLY + FREEHOLD, 
                       data=condo_resale.sp, 
                       bw=bw.fixed, 
                       kernel = 'gaussian', 
                       longlat = FALSE)

gwr.fixed

```

The report above shows that the AICc value of the Geographically Weighted Regression model is 42263.61, which is significantly lower than that of the Global Regression model (i.e., 42967.14).

### Building adaptive bandwidth GWR model

Next, we'll calibrate a gwr-based hedonic pricing model using adaptive bandwidth approach.

**Computing the adaptive bandwidth**

We'll again use CV approach to determine the optimal bandwidth first.

```{r}
bw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + 
                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + 
                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + 
                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + 
                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                      data=condo_resale.sp, 
                      approach="CV", 
                      kernel="gaussian", 
                      adaptive=TRUE, 
                      longlat=FALSE)

```

The result above shows that the optimal bandwidth is 30 neighbours.

**Constructing the adaptive bandwidth gwr model**

Now we'll build the gwr-based hedonic pricing model using adaptive bandwidth and gaussian kernel.

```{r}
gwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + 
                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + 
                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + 
                            PROX_BUS_STOP + NO_Of_UNITS + 
                            FAMILY_FRIENDLY + FREEHOLD, 
                          data=condo_resale.sp, bw=bw.adaptive, 
                          kernel = 'gaussian', 
                          adaptive=TRUE, 
                          longlat = FALSE)

gwr.adaptive

```

The report above shows that the AICc value of the Geographically Weighted Regression model is 41982.22, which is the lowest among the three models.

### Visualizing GWR output

In addition to the residuals, the model output also contains the following information:

-   Condition Number: checks for local collinearity. If the condition number exceeds 30, it indicates strong local collinearity which inplies unreliable results.

-   Local R2: ranges from 0 to 1, and indicates how well the local regression model fits the observed y values. The higher the value is, the better the model is. Local R2 can also tell us where the model predicts well and where not, which could provide clues about important variable that may be missing from the regression model.

-   Predicted: the fitted y values

-   Residuals: the difference between the observed y values and the fitted y values. Standardized residual should have mean 0 and standard deviation 1. They could be used to plot a cold-to-hot rendered map.

-   Coefficient Standard Error: measures the reliability of each coefficient estimate. The smaller the standard error, the better the coefficient estimates. Large standard errors may indicate local collinearity.

All these information is stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object in SDF format.

### Converting SDF into sf data.frame

In order to visualize the content in SDF, we need to first convert it into sf data.frame.

```{r}
condo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%
  st_transform(crs=3414)

```

```{r}
condo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)

condo_resale.sf.adaptive.svy21  

```

```{r}
gwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)

condo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))

```

```{r}
glimpse(condo_resale.sf.adaptive)

```

```{r}
summary(gwr.adaptive$SDF$yhat)

```

The report above shows the summary statistics of the fitted y values.

### Visualizing local R2

Let's visualize the local R2 in an interactive point symbol map.

```{r}
tmap_mode("view")

tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "Local_R2",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))

tmap_mode("plot")

```

The plot above shows that the local R2 are high in most of the area, except a few planning area in the middle.

**By URA planning region**

We could plot the local R2 for only the central region.

```{r}
tm_shape(mpsz_svy21[mpsz_svy21$REGION_N=="CENTRAL REGION", ])+
  tm_polygons()+
tm_shape(condo_resale.sf.adaptive) + 
  tm_bubbles(col = "Local_R2",
           size = 0.15,
           border.col = "gray60",
           border.lwd = 1)

```

The plot above shows that the area where low R2 was reported are at the top of the central region.

### Visualizing coefficient estimates

We could also create an synced interactive point symbol map to compare the standard error and t test statistic.

```{r}
tmap_mode("view")

AREA_SQM_SE <- tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "AREA_SQM_SE",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))

AREA_SQM_TV <- tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "AREA_SQM_TV",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))

tmap_arrange(AREA_SQM_SE, AREA_SQM_TV, 
             asp=1, ncol=2,
             sync = TRUE)

tmap_mode("plot")

```

The plot above shows that the standard error of AREA_SQM variable is low in most of the area, which indicates the variable is reliable.

## Reference

Singapore Land Authority. (n.d.). *Plane Coordinate System - SVY21*. <https://app.sla.gov.sg/sirent/About/PlaneCoordinateSystem>
